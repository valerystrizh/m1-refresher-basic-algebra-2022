{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often conceptually convenient to talk about the *inverse* $A^{-1}$ of a matrix $A$, which exists **for any non-singular square matrix**.   This is the matrix such that $x = A^{-1}b$ solves $Ax = b$ for any $b$.   The inverse is conceptually convenient becuase it allows us to move matrices around in equations *almost* like numbers (except that matrices don't commute!).\n",
    "\n",
    "Another way of defining the inverse of a matrix involves the *identity* matrix $I$.   Here is a $ 5 \\times 5$ identity matrix:\n",
    "\n",
    "$$\n",
    "I = \\begin{pmatrix} 1&0&0&0&0 \\\\ 0&1&0&0&0 \\\\ 0&0&1&0&0 \\\\ 0&0&0&1&0 \\\\ 0&0&0&0&1 \\end{pmatrix}\n",
    "= \\begin{pmatrix} e_1 & e_2 & e_3 & e_4 & e_5 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where the columns $e_1 \\cdots e_5$ of $I$ are the **unit vectors** in each component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse matrix $A^{-1}$ is the matrix such that $A^{-1} A = A A^{-1} = I$.\n",
    "\n",
    "Why does this correspond to solving $Ax=b$?  Multiplying both sides on the *left* by $A^{-1}$ (multiplying on the *right* would make no sense: we can't multiply vector√ómatrix!), we get \n",
    "\n",
    "$$\n",
    "A^{-1}Ax=Ix = x = A^{-1}b\n",
    "$$\n",
    "\n",
    "How do we find $A^{-1}$?  The key is the equation $A A^{-1} = I$, which looks just like $AX=B$ for the **right-hand sides consisting of the columns of the identity matrix**, i.e. the unit vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, $AB \\ne BA$ for two matrices $A$ and $B$.  Why can we multiply $A$ by $A^{-1}$ on either the left or right and get the same answer $I$?  It is fairly easy to see why:\n",
    "\n",
    "$$\n",
    "A A^{-1} = I \\implies A A^{-1} A = IA = A = A (A^{-1} A)\n",
    "$$\n",
    "\n",
    "Since $A (A^{-1} A) = A$, and $A$ is non-singular (so there is a unique solution to this system of equations), we must have $A^{-1} A = I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix inverses are funny, however:\n",
    "\n",
    "* Inverse matrices are very convenient in *analytical* manipulations, because they allow you to move matrices from one side to the other of equations easily.\n",
    "\n",
    "* Inverse matrices are **almost never computed** in \"serious\" numerical calculations.  Whenever you see $A^{-1} B$ (or $A^{-1} b$), when you go to *implement* it on a computer you should *read* $A^{-1} B$ as \"solve $AX = B$ by some method.\" e.g. solve it by `A \\ B` or by first computing the LU factorization of $A$ and then using it to solve $AX = B$.\n",
    "\n",
    "One reason that you don't usually compute inverse matrices is that it is wasteful: once you have $PA=LU$, you can solve $AX=B$ directly without bothering to find $A^{-1}$, and computing $A^{-1}$ requires much more work if you only have to solve a few right-hand sides.\n",
    "\n",
    "Another reason is that for many special matrices, there are ways to solve $AX=B$ *much* more quickly than you can find $A^{-1}$.   For example, many large matrices in practice are [sparse](https://en.wikipedia.org/wiki/Sparse_matrix) (mostly zero), and often for sparse matrices you can arrange for $L$ and $U$ to be sparse too.  Sparse matrices are much more efficient to work with than general \"dense\" matrices because you don't have to multiply (or even store) the zeros. Even if $A$ is sparse, however, $A^{-1}$ is usually non-sparse, so you lose the special efficiency of sparsity if you compute the inverse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about inverse matrices:\n",
    "\n",
    "1. The matrix must be square in order for this definition to make sense.  If $A$ is not square, it is impossible for both \n",
    "$A^{-1}A$ and $AA^{-1}$ to be defined.\n",
    "2. Not all matrices have inverses.  Matrices that do have inverses are called **invertible** matrices.  Matrices that do not have inverses are called **non-invertible**, or **singular**, matrices.\n",
    "3. If a matrix is invertible, its inverse is unique.\n",
    "\n",
    "Now *if we know* $A^{-1}$, we can solve the system $AX=B$ by multiplying both sides by $A^{-1}$.\n",
    "\n",
    "$$\n",
    "A^{-1}AX = A^{-1}B\n",
    "$$\n",
    "\n",
    "Then $A^{-1}AX = IX = X$, so the solution to the system is $X=A^{-1}B$.  Unfortunately, it is typically not easy to find $A^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverses and products\n",
    "\n",
    "Inverses have a special relationship to matrix products:\n",
    "$$\n",
    "(AB)^{-1} = B^{-1} A^{-1}\n",
    "$$\n",
    "\n",
    "The reason for this is that we must have $(AB)^{-1} AB = I$, and it is easy to see that $B^{-1} A^{-1}$ does the trick.  Equivalently, $AB$ is the matrix that first multiplies by $B$ then by $A$; to invert this, we must *reverse the steps*: first multiply by the inverse of $A$ and then by the inverse of $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity of Matrix Operations\n",
    "\n",
    "With a little effort, we can figure out that the **number of arithmetic operations** for an $n\\times n$ matrix **scales proportional to** (for large $n$):\n",
    "\n",
    "* $n^2$ for: matrix `*` vector $Ax$, or solving a *triangular* system like $Ux=c$ or $Lc=b$ (back/forward substitution)\n",
    "* $n^3$ for: matrix `*` matrix $AB$, LU factorization $PA=LU$, or solving a triangular system with $n$ right-hand sides like computing $A^{-1}$ from the LU factorization.\n",
    "\n",
    "(In computer science, we would say that these have \"complexity\" $\\Theta(n^2)$ and $\\Theta(n^3)$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose, Permutations, and Orthogonality\n",
    "\n",
    "One special type of matrix for which we can solve problems much more quickly is a permutation matrix, introduced in the lecture on $PA=LU$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse of any permutation matrix $P$ turns out to be its [transpose](https://en.wikipedia.org/wiki/Transpose) $P^T$: we just swap rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason this works is that $P^T P$ computes the dot products of *all the columns* of $P$ with *all of the columns*, and the columns of $P$ are [orthonormal](https://en.wikipedia.org/wiki/Orthonormality) (orthogonal with length 1).  We say that $P$ is an example of an [\"orthogonal\" matrix or a \"unitary\" matrix](https://en.wikipedia.org/wiki/Unitary_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposes and products\n",
    "\n",
    "Transposes are important in linear algebra because they have a special relationship to matrix and vector products:\n",
    "$$\n",
    "(AB)^T = B^T A^T\n",
    "$$\n",
    "and hence for a dot product (inner product) $x^T y$\n",
    "$$\n",
    "x \\mbox{ dot } (Ay) = x^T (Ay) = (A^T x)^T y = (A^T x) \\mbox{ dot } y\n",
    "$$\n",
    "We can even turn the second step around and use this as the *definition* of a transpose: a transpose is *what \"moves\" a matrix from one side to the other of a dot product.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposes and inverses\n",
    "\n",
    "From the above property, we have:\n",
    "$$\n",
    "(A A^{-1})^T = (A^{-1})^T A^T = I^T = I\n",
    "$$\n",
    "and it follows that:\n",
    "$$\n",
    "(A^{-1})^T = (A^T)^{-1}\n",
    "$$\n",
    "The *transpose of the inverse* is the *inverse of the transpose*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Matrix Inverses in General\n",
    "\n",
    "How do we find $A^{-1}$?  The key is the equation $A A^{-1} = I$, which looks just like $AX=B$ for the **right-hand sides consisting of the columns of the identity matrix**, i.e. the unit vectors.   So, we just solve $Ax=e_i$ for $i=1,\\ldots,5$.\n",
    "\n",
    "We take $C$ as an example matrix, and consider how we might build the inverse.\n",
    "\n",
    "$$\n",
    "C = \\left[ \\begin{array}{rrrr} 1 & 0 & 2 & -1 \\\\ 3 & 1 & -3 & 2 \\\\ 2 & 0 & 4 & 4 \\\\ 2 & 1 & -1 & -1 \\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Let's think of the matrix product $CC^{-1}= I$ in terms of the columns of $C^{-1}$.  We put focus on the third column as an example, and label those unknown entries with $y_i$.  The \\* entries are uknown as well, but we will ignore them for the moment.\n",
    "\n",
    "$$\n",
    "CC^{-1}=\n",
    "\\left[ \\begin{array}{rrrr} 1 & 0 & 2 & -1 \\\\ 3 & 1 & -3 & 2 \\\\ 2 & 0 & 4 & 4 \\\\ 2 & 1 & -1 & -1 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{rrrr} * & * & y_1& * \\\\ * & * & y_2 & * \\\\ * & * & y_3 & * \\\\ * & * & y_4 & *  \\end{array}\\right]=\n",
    "\\left[ \\begin{array}{rrrr} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]=\n",
    "I\n",
    "$$\n",
    "\n",
    "Recall now that $C$ multiplied by the third column of $C^{-1}$ produces the third column of $I$.  This gives us a linear system to solve for the $y_i$.\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{rrrr} 1 & 0 & 2 & -1 \\\\ 3 & 1 & -3 & 2 \\\\ 2 & 0 & 4 & 4 \\\\ 2 & 1 & -1 & -1 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{r}  y_1 \\\\  y_2  \\\\ y_3 \\\\ y_4  \\end{array}\\right]=\n",
    "\\left[ \\begin{array}{r}  0 \\\\  0  \\\\ 1 \\\\ 0  \\end{array}\\right]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse matrices with SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.33333333e-01  5.00000000e-01 -1.66666667e-01 -5.00000000e-01]\n",
      " [-2.08333333e+00 -1.25000000e+00  6.66666667e-01  2.25000000e+00]\n",
      " [-8.33333333e-02 -2.50000000e-01  1.66666667e-01  2.50000000e-01]\n",
      " [-3.33333333e-01 -6.16790569e-18  1.66666667e-01  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as sla\n",
    "\n",
    "C = np.array([[1,0,2,-1],[3,1,-3,2],[2,0,4,4],[2,1,-1,-1]])\n",
    "C_inverse = sla.inv(C)\n",
    "print(C_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing a non-invertible matrix to $\\texttt{inv}$ will result in an error being raised by the Python interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *symmetric* matrix $S$ is a matrix that equals its transpose: $S = S^T$.   Suppose that $A=A^T$ and $B=B^T$ are two symmetric matrices, and $C$ is some other matrix (possibly nonsymmetric), all of the same size $m\\times m$.  Which of the following are certainly symmetric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "* $A^2 - B^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "* $(A+B)(A-B)$ (note that this does *not* generally equal $A^2 - B^2$ ... why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "* $C^T A C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "* $A^T C A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n",
    "* $ABA$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:**\n",
    "* $C + C^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:**\n",
    "* $C - C^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:**\n",
    "* $ABAB$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
