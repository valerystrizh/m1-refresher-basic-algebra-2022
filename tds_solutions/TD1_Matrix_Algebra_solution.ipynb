{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **matrix** a is two-dimensional array of numbers.  When we do computations with matrices using NumPy, we will be using arrays just as we did before.  Let's write down some of examples of matrices and give them names.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rr} 1 & 3 \\\\ 2 & 1 \\end{array}\\right] \\hspace{1cm} \n",
    "B = \\left[ \\begin{array}{rrr} 3 & 0 & 4 \\\\ -1 & -2 & 1 \\end{array}\\right] \\hspace{1cm}\n",
    "C = \\left[ \\begin{array}{rr} -2 & 1 \\\\ 4 & 1 \\end{array}\\right] \\hspace{1cm}\n",
    "D = \\left[ \\begin{array}{r} 2 \\\\ 6 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "When discussing matrices it is common to talk about their dimensions, or shape, by specifying the number of rows and columns.  The number of rows is usually listed first.  For our examples, $A$ and $C$ are $2\\times 2$ matrices, $B$ is a $2 \\times 3$ matrix, and $D$ is a $2 \\times 1 $ matrix.  Matrices that have only 1 column, such as $D$, are commonly referred to as **vectors**.  We will adhere to this convention as well, but do be aware that when we make statements about matrices, we are also making statements about vectors even if we don't explicitly mention them.  We will also adopt the common convention of using uppercase letters to name matrices.\n",
    "\n",
    "It is also necessary to talk about the individual entries of matrices.  The common notation for this is a lowercase letter with subscripts to denote the position of the entry in the matrix.  So $b_{12}$ refers to the 0 in the first row and second column of the matrix $B$.  If we are talking about generic positions, we might use variables in the subscripts, such as $a_{ij}$.\n",
    "\n",
    "Let's create these matrices as NumPy arrays before further discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 3],[2,1]])\n",
    "B = np.array([[3, 0, 4],[-1, -2, 1]])\n",
    "C = np.array([[-2, 1],[4, 1]])\n",
    "D = np.array([[2],[6]])\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful for us to access the dimensions of our arrays.  When the array is created, this information gets stored as part of the array object and can be accessed with a method called $\\texttt{shape}$.  If $\\texttt{B}$ is an array, the object $\\texttt{B.shape}$ is itself an array that has two entries.  The first (*with index 0!*) is the number of rows, and the second (*with index 1!*) is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array B has 2 rows.\n",
      "Array B has 3 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"Array B has\",B.shape[0],\"rows.\")\n",
    "print(\"Array B has\",B.shape[1],\"columns.\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on matrices\n",
    "\n",
    "There are three algebraic operations for matrices that we will need to perform.  For our definitions let us suppose that $A$ and $C$ are $m \\times n$ matrices, $B$ is an $n \\times k$ matrix, and $c$ is a number.  When discussing algebra involving matrices and numbers, the numbers are usually referred to as **scalars**. \n",
    "\n",
    "1. A matrix of any shape can be multiplied by a scalar.  The result is that all entries are multiplied by that scalar.  Using the subscript notation, we would write\n",
    "\n",
    "$$\n",
    "(cA)_{ij} = ca_{ij}\n",
    "$$\n",
    "\n",
    "2. Two matrices that *have the same shape* can be added.  The result is that all corresponding entries are added.\n",
    "\n",
    "$$\n",
    "(A+C)_{ij} = a_{ij} + c_{ij}\n",
    "$$\n",
    "\n",
    "3. If the number of columns of matrix $A$ is equal to the number of rows of matrix $B$, the matrices can be multiplied in the order $A$, $B$.  The result will be a new matrix $AB$, that has the same number of rows as $A$ and the same number of columns as $B$.  The entries $(AB)_{ij}$ will be the following combination of the entries of row $i$ of $A$ and column $j$ of $B$.\n",
    "\n",
    "$$\n",
    "(AB)_{ij} = \\sum_{k=1}^n a_{ik}b_{kj}\n",
    "$$\n",
    "\n",
    "The last operation, known as **matrix multiplication**, is the most complex and least intuitive of the three.  No doubt this last formula is a bit intimidating the first time we read it.  Let's give some examples to clarify.\n",
    "\n",
    "1.  The multiplication of a number and a matrix:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "3A = 3\\left[ \\begin{array}{rr} 1 & 3 \\\\ 2 & 1 \\end{array}\\right] \n",
    "= \\left[ \\begin{array}{rr} 3 & 9 \\\\ 6 & 3 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "2. The sum of two matrices of the same shape:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A + C = \\left[ \\begin{array}{rr} 1 & 3 \\\\ 2 & 1 \\end{array}\\right] + \n",
    "\\left[ \\begin{array}{rr} -2 & 1 \\\\ 4 & 1 \\end{array}\\right] \n",
    "= \\left[ \\begin{array}{rr} -1 & 4 \\\\ 6 & 2 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "3.  The multiplication of two matrices:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AB = \\left[ \\begin{array}{rr} 1 & 3 \\\\ 2 & 1 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{rrr} 3 & 0 & 4 \\\\ -1 & -2 & 1 \\end{array}\\right]\n",
    " = \\left[ \\begin{array}{rrr} 0 & -6 & 7  \\\\  5 & -2 & 9  \\end{array}\\right]\n",
    " \\end{equation}\n",
    "$$\n",
    " \n",
    "To clarify what happens in the  matrix multiplication, lets calculate two of the entries in detail.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "(AB)_{12} & = & 1\\times 0 + 3 \\times (-2) = -6 \\\\\n",
    "(AB)_{23} & = & 2 \\times 4 + 1 \\times 1 = 9\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "These matrix operations are all built into NumPy, but we have to use the symbol $\\texttt{@}$ instead of $\\texttt{*}$ for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 9]\n",
      " [6 3]] \n",
      "\n",
      "[[-1  4]\n",
      " [ 6  2]] \n",
      "\n",
      "[[ 0 -6  7]\n",
      " [ 5 -2  9]]\n"
     ]
    }
   ],
   "source": [
    "print(3*A,'\\n')\n",
    "print(A+C,'\\n')\n",
    "print(A@B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of matrix operations\n",
    "\n",
    "It is useful to observe that some common algebraic properties hold true for matrix multiplication.  Let $A$, $B$, and $C$ be matrices, and $k$ be a scalar.  The associative and distributive properties stated here hold for matrix multiplication.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "k(A+B) = kA + kB\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C(A+B) = CA + CB\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A(BC) = (AB)C\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "These statements only make sense of course if the matrices have dimensions that allow for the operations.\n",
    "\n",
    "It is also worth noting that the commutative property does not generally hold for matrix multiplication.  Suppose for example that $A$ and $B$ are both $3\\times 3$ matrices.  It is **not true in general** that $AB = BA$.  One example with random matrices is enough to prove this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6  12 -24]\n",
      " [  2  -2  24]\n",
      " [ -2 -20  -8]]\n",
      "\n",
      "\n",
      "[[  1 -21 -20]\n",
      " [ 25  -9   4]\n",
      " [ -6   0   4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(-5,5,size=(3,3))\n",
    "B = np.random.randint(-5,5,size=(3,3))\n",
    "\n",
    "print(A@B)\n",
    "print('\\n')\n",
    "print(B@A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix transposes\n",
    "\n",
    "Another common idea that we will find useful is that of the matrix transpose.  The **transpose** of a matrix $A$ is another matrix, $A^T$, defined so that its columns are the rows of $A$.  To build $A^T$, we simple swap the row index with the column index for every entry, $a^T_{ij} = a_{ji}$.  Two examples should be enough to clarify this definition.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rrr} 5 & 4 & 0 \\\\ 1 & 8 & 3 \\\\ 6 & 7 & 2\\end{array}\\right] \\hspace{1cm}\n",
    "A^T = \\left[ \\begin{array}{rrr} 5 & 1 & 6 \\\\ 4 & 8 & 7 \\\\ 0 & 3 & 2\\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B = \\left[ \\begin{array}{rrr} 1 & 2 & 7 & 0 \\\\ 3 & 1 & 5 & 2 \\\\ 4 & 9 & 8 & 6\\end{array}\\right] \\hspace{1cm}\n",
    "B^T = \\left[ \\begin{array}{rrr} 1 & 3 & 4 \\\\ 2 & 1 & 9 \\\\ 7 & 5 & 8 \\\\ 0 & 2 & 6\\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "NumPy array objects have a method named $\\texttt{transpose}$ for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4 0]\n",
      " [1 8 3]\n",
      " [6 7 2]]\n",
      "\n",
      "\n",
      "[[5 1 6]\n",
      " [4 8 7]\n",
      " [0 3 2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[5, 4, 0],[1, 8, 3],[6, 7, 2]])\n",
    "\n",
    "## Note that the tranpose method must be called with (), the same as a function with no arguments.\n",
    "A_T = A.transpose()\n",
    "\n",
    "print(A)\n",
    "print('\\n')\n",
    "print(A_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a matrix $A$ is equal to its own transpose, it has the property of being symmetric across its main diagonal. For this reason a matrix $A$ is said to be **symmetric** if $A = A^T$. Equivalently, we can say that $A$ is symmetric if $a_{ij} = a_{ji}$ for every entry $a_{ij}$ in the matrix.  The matrix $P$ below is one such example.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P = \\left[ \\begin{array}{rrr} 1 & 0 & 6 \\\\ 0 & 3 & 5 \\\\ 6 & 5 & -2\\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Similarly, we say that a matrix $A$ is **skew-symmetric** if $A^T = -A$ (equivalently $a_{ij} = -a_{ji}$ for every entry $a_{ij}$ in $A$). The matrix $Q$ below is a skew-symmetric matrix.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Q = \\left[ \\begin{array}{rrr} 0 & 1 & -4 \\\\ -1 & 0 & 5 \\\\ 4 & -5 & 0\\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to linear systems\n",
    "\n",
    "A very important example of matrix multiplication is that where a known matrix multiplies an *unknown* vector to produce a known vector.  If we let $A$ be the known matrix, $B$ be the known vector, and $X$ be the unknown vector, we can write the matrix equation $AX=B$ to describe this scenario.  Let's write a specific example.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A= \\left[ \\begin{array}{rrr} 1 & 3 & -2 \\\\ 5 & 2 & 0 \\\\ 4 & 2 & -1 \\\\ 2 & 2 & 0 \\end{array}\\right] \\hspace{1cm}\n",
    "X= \\left[ \\begin{array}{r} x_1 \\\\ x_2 \\\\ x_3 \\end{array}\\right] \\hspace{1cm}\n",
    "B= \\left[ \\begin{array}{r} 0 \\\\ 10 \\\\ 7 \\\\ 4  \\end{array}\\right] \\hspace{1cm}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AX = \\left[ \\begin{array}{rrr} 1 & 3 & -2 \\\\ 5 & 2 & 0 \\\\ 4 & 2 & -1 \\\\ 2 & 2 & 0 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{r} x_1 \\\\ x_2 \\\\ x_3 \\end{array}\\right]=\n",
    "\\left[ \\begin{array}{r} 0\\\\ 10 \\\\ 7 \\\\ 4  \\end{array}\\right]= B\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "If we apply the definition of matrix multiplication we see that this single matrix equation $AX=B$ in fact represents a system of linear equations.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "x_1 + 3x_2 - 2x_3 & = & 0\\\\\n",
    "5x_1 + 2x_2 \\quad\\quad & = & 10 \\\\\n",
    "4x_1 + 2x_2 - x_3 & = & 7 \\\\\n",
    "2x_1 + 2x_2 \\quad\\quad & = & 4\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "In this context, the matrix $A$ is known as the **coefficient matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity matrices\n",
    "\n",
    "An **identity matrix** is a square matrix that behaves similar to the number 1 with respect to ordinary multiplication.  Identity matrices, labeled with $I$, are made up of ones along the main diagonal, and zeros everywhere else.  Below is the $4 \\times 4$ version of $I$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "I = \\left[ \\begin{array}{ccc} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "If $A$ is any other $4 \\times 4$ matrix, multiplication with $I$ will produce $A$.  Furthermore it doesn't matter in this case which order the multiplication is carried out.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AI = IA = A\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The NumPy function $\\texttt{eye}$ generates an identity matrix of the specified size.  Note we only need to provide $\\texttt{eye}$ with one parameter since the identity matrix must be square.  We show here the product of $I$ with a random $5\\times 5$ matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "I5 = np.eye(5)\n",
    "print(I5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -8  -6  -4  -5  -3]\n",
      " [  9   7   0  -9  -4]\n",
      " [  0   7   0  -3  -8]\n",
      " [  2 -10  -4   0  -1]\n",
      " [  4  -8   5   3   1]]\n",
      "\n",
      "\n",
      "[[ -8.  -6.  -4.  -5.  -3.]\n",
      " [  9.   7.   0.  -9.  -4.]\n",
      " [  0.   7.   0.  -3.  -8.]\n",
      " [  2. -10.  -4.   0.  -1.]\n",
      " [  4.  -8.   5.   3.   1.]]\n",
      "\n",
      "\n",
      "[[ -8.  -6.  -4.  -5.  -3.]\n",
      " [  9.   7.   0.  -9.  -4.]\n",
      " [  0.   7.   0.  -3.  -8.]\n",
      " [  2. -10.  -4.   0.  -1.]\n",
      " [  4.  -8.   5.   3.   1.]]\n"
     ]
    }
   ],
   "source": [
    "R = np.random.randint(-10,10,size=(5,5))\n",
    "print(R)\n",
    "print('\\n')\n",
    "print(R@I5)\n",
    "print('\\n')\n",
    "print(I5@R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-vector multiplication\n",
    "\n",
    "One special case of matrix multiplication deserves close attention, the case where one of the matrices is a vector.  This case is so important that it is commonly discussed separately and given a special name, **matrix-vector multiplication**.  Let's suppose that $P$ is our matrix and that its shape is $n \\times m$, and $Y$ is our vector which is $m \\times 1$.  The product $PY$ then is a $n \\times 1$ vector.  It is the relationship between this new vector and the columns of the matrix $P$ that makes this situation important.\n",
    "\n",
    "Let's have a look with a specific example.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P = \\left[ \\begin{array}{rrr} 1 & 3 & -2 \\\\ 5 & 2 & 0 \\\\ 4 & 2 & -1 \\\\ 2 & 2 & 0 \\end{array}\\right]\\hspace{1cm}\n",
    "Y = \\left[ \\begin{array}{r} 2 \\\\ -3 \\\\ 4 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this case of matrix-vector multiplication, we can package the calculation a bit differently to better understand what is happening.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "PY = \\left[ \\begin{array}{rrr} 1 & 3 & -2 \\\\ 5 & 2 & 0 \\\\ 4 & 2 & -1 \\\\ 2 & 2 & 0 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{r} 2 \\\\ -3 \\\\ 4 \\end{array}\\right]=\n",
    "2\\left[ \\begin{array}{r} 1 \\\\ 5 \\\\ 4 \\\\ 2 \\end{array}\\right] -\n",
    "3\\left[ \\begin{array}{r} 3 \\\\ 2 \\\\ 2 \\\\ 2 \\end{array}\\right] +\n",
    "4\\left[ \\begin{array}{r} -2 \\\\ 0 \\\\ -1 \\\\ 0 \\end{array}\\right] =\n",
    "\\left[ \\begin{array}{r} -15\\\\ 4 \\\\ -2 \\\\ -2  \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This is the same operation that we were doing before, but now we see that this product is a result of adding the columns of $P$ after first multiplying each by the corresponding entry in $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication by columns\n",
    "\n",
    "We can extend the calculation of matrix-vector multiplication to better understand exactly what is produced by matrix-matrix multiplication.  Suppose for example that $Y$ from the earlier calculation was actually the third column of a $3\\times 4$ matrix $C$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C = \\left[ \\begin{array}{rrrr} * & * & 2 & * \\\\ * & * & -3 & * \\\\ * & * & 4 & *\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The third column of the product $PC$ will be exactly $PY$!  The other columns of $PC$ will be the products of $P$ with the corresponding columns of $C$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "PC = \\left[ \\begin{array}{rrrr} * & * & -15 & * \\\\ * & * & 4 & * \\\\* & * & -2 & *  \\\\ * & * & -2 & *\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discussion offers a great opportunity to learn how to perform operations on portions of NumPy arrays using a feature called **slicing**.  Let's build the matrices $P$ and $C$, and then define $X$ as a **subarray** of $C$.  To create a subarray of $C$, we use the syntax $\\texttt{C[a:b,c:d]}$.  This will create an array object that has shape $(b-a)\\times(d-c)$ and contains the entries of rows $a$ to $b-1$ and columns $c$ to $d-1$ of $C$.    \n",
    "\n",
    "Specifically, we want $X$ to include all rows of $C$, but only the third column (which has Python index 2!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3 -2]\n",
      " [ 5  2  0]\n",
      " [ 4  2 -1]\n",
      " [ 2  2  0]] \n",
      "\n",
      "[[ 0  6  2  6]\n",
      " [-1  1 -3  4]\n",
      " [ 0  2  4  8]] \n",
      "\n",
      "[[ 2]\n",
      " [-3]\n",
      " [ 4]] \n",
      "\n",
      "[[-15]\n",
      " [  4]\n",
      " [ -2]\n",
      " [ -2]]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[1, 3, -2],[5, 2, 0],[4, 2, -1],[2, 2, 0]])\n",
    "C = np.array([[0, 6, 2, 6],[-1, 1, -3, 4],[0, 2, 4, 8]])\n",
    "X = C[0:3,2:3]\n",
    "print(P,'\\n')\n",
    "print(C,'\\n')\n",
    "print(X,'\\n')\n",
    "print(P@X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on array slicing:\n",
    "\n",
    "- Another way to select all rows (or all columns) from an array is to use : without any numbers.  In our example above, we could have used the following line of code to produce the same result.  Try it out by editing the cell above!\n",
    "```\n",
    "X = C[:,2:3]\n",
    "```\n",
    "- If we only want to select a single row or column, it is tempting to try a line of code like the following.\n",
    "```\n",
    "X = C[:,2]\n",
    "```\n",
    "this is indeed valid code, but the array $X$ is not exactly what we expect.  Instead we get an array with the correct entries, but not the correct shape.  It is possible to make this work, but let's avoid this complication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Calculate $-2E$, $G+F$, $4F-G$, $HG$, and $GE$ using the following matrix definitions.  Do the exercise on paper first, then check by doing the calculation with NumPy arrays.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E = \\left[ \\begin{array}{r} 5 \\\\ -2 \\end{array}\\right] \\hspace{1cm} \n",
    "F = \\left[ \\begin{array}{rr} 1 & 6 \\\\ 2 & 0 \\\\ -1 & -1 \\end{array}\\right] \\hspace{1cm}\n",
    "G = \\left[ \\begin{array}{rr} 2 & 0\\\\ -1 & 3 \\\\ -1 & 6 \\end{array}\\right] \\hspace{1cm}\n",
    "H = \\left[ \\begin{array}{rrr} 3 & 0 & 1 \\\\ 1 & -2 & 2 \\\\ 3 & 4 & -1\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10]\n",
      " [  4]] \n",
      "\n",
      "[[ 3  6]\n",
      " [ 1  3]\n",
      " [-2  5]] \n",
      "\n",
      "[[  2  24]\n",
      " [  9  -3]\n",
      " [ -3 -10]] \n",
      "\n",
      "[[5 6]\n",
      " [2 6]\n",
      " [3 6]] \n",
      "\n",
      "[[ 10]\n",
      " [-11]\n",
      " [-17]]\n"
     ]
    }
   ],
   "source": [
    "E = np.array([[5],[-2]])\n",
    "F = np.array([[1,6],[2,0],[-1,-1]])\n",
    "G = np.array([[2,0],[-1,3],[-1,6]])\n",
    "H = np.array([[3,0,1],[1,-2,2],[3,4,-1]])\n",
    "print(-2*E,'\\n')\n",
    "print(G+F,'\\n')\n",
    "print(4*F-G,'\\n')\n",
    "print(H@G,'\\n')\n",
    "print(G@E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Define NumPy arrays for the matrices $H$ and $G$ given below.  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "H = \\left[ \\begin{array}{rrr} 3 & 3 & -1  \\\\ -3 & 0 & 8 \\\\  1 & 6 & 5 \\end{array}\\right]\\hspace{2cm}\n",
    "G = \\left[ \\begin{array}{rrrr} 1 & 5 & 2 & -3 \\\\ 7 & -2 & -3 & 0 \\\\ 2 & 2 & 4 & 6\\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$(a)$ Multiply the second and third column of $H$ with the first and second row of $G$.  Use slicing to make subarrays.  Does the result have any relationship to the full product $HG$?\n",
    "\n",
    "$(b)$ Multiply the first and second row of $H$ with the second and third column of $G$.  Does this result have any relationship to the full product $HG$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   7  -7 -15]\n",
      " [ 13   1  26  57]\n",
      " [ 53   3   4  27]] \n",
      "\n",
      "[[ -4  17   9  -9]\n",
      " [ 56 -16 -24   0]\n",
      " [ 41  20  -3 -18]] \n",
      "\n",
      "[[ 7 -7]\n",
      " [ 1 26]]\n"
     ]
    }
   ],
   "source": [
    "H = np.array([[3,3,-1],[-3,0,8],[1,6,5]])\n",
    "G = np.array([[1,5,2,-3],[7,-2,-3,0],[2,2,4,6]])\n",
    "\n",
    "print(H@G,'\\n')\n",
    "print(H[:,1:3]@G[0:2,:],'\\n')\n",
    "print(H[0:2,:]@G[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second product is a $2 \\times 2$ matrix that is a **submatrix** of the larger matrix $HG$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Generate a $4\\times 4$ matrix $B$ with random integer entries.  Compute matrices $P = \\frac12(B+B^T)$ and $Q = \\frac12(B-B^T)$.  Rerun your code several times to get different matrices.  What do you notice about $P$ and $Q$?  Explain why it must always be true.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   9 -10  -8]\n",
      " [  0  -5  -5  -5]\n",
      " [  7  -5   3   1]\n",
      " [ -6 -10   3  -6]] \n",
      "\n",
      "[[ 3.   4.5 -1.5 -7. ]\n",
      " [ 4.5 -5.  -5.  -7.5]\n",
      " [-1.5 -5.   3.   2. ]\n",
      " [-7.  -7.5  2.  -6. ]] \n",
      "\n",
      "[[ 0.   4.5 -8.5 -1. ]\n",
      " [-4.5  0.   0.   2.5]\n",
      " [ 8.5  0.   0.  -1. ]\n",
      " [ 1.  -2.5  1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "B = np.random.randint(size=(4,4),high=10,low=-10)\n",
    "P = 1/2*(B+B.transpose())\n",
    "Q = 1/2*(B-B.transpose())\n",
    "print(B,'\\n')\n",
    "print(P,'\\n')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P$ is always a symmetric matrix and $Q$ is always a skew-symmetric matrix.\n",
    "    \n",
    "To see why $P$ is always symmetric, recall that $P$ being symmetric is equivalent to saying $p_{ij} = p_{ji}$ for all entries $p_{ij}$ in $P$. Now notice that \n",
    "\n",
    "$$\n",
    "\\begin{equation}   \n",
    "p_{ij} = \\frac{1}{2}(b_{ij} + b_{ji}) = \\frac{1}{2}(b_{ji} + b_{ij}) = p_{ji}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and therefore $P$ is symmetric.\n",
    "   \n",
    "To see why $Q$ is always skew-symmetric, recall that $Q$ being skew-symmetric is equivalent to saying $q_{ij} = -q_{ji}$ for all entries $q_{ij}$ in $Q$. Now notice that\n",
    "   \n",
    "$$\n",
    "\\begin{equation}\n",
    "q_{ij} = \\frac{1}{2}(b_{ij} - b_{ji}) = -\\frac{1}{2}(b_{ji} - b_{ij}) = -q_{ji}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and therefore $Q$ is skew-symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Find an upper-triangular $U$ (not diagonal) with $U^2 = I$ and $U = U^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 1: Brute force** \n",
    "Here is a \"brute force\" way of solving this problem, by just setting up a set of equations for the entries of $U$ and solving them:\n",
    "\n",
    "Let's look for a $2 \\times 2$ matrix $U$ with the specified properties.  Give the entries of $U$ names: $$U = \\begin{pmatrix} u_{11} & u_{12} \\\\ 0 & u_{21}\\end{pmatrix}.$$  Take a look at the square of $U$: $$U^2 = \\begin{pmatrix} u_{11}^2 & u_{11}u_{12} + u_{12}u_{22} \\\\ 0 & u_{22}^2\\end{pmatrix} = \\begin{pmatrix} u_{11}^2 & (u_{11} + u_{22})u_{12} \\\\ 0 & u_{22}^2\\end{pmatrix}.$$  We need that this matrix above is $I$ (of course, $U^2 = I$ and $U = U^{-1}$ are equivalent, so we can just focus on the first one).  We need $u_{11}^2 = u_{22}^2 = 1$, which means that each of $u_{11}$ and $u_{22}$ is either 1 or -1.  We also need that $(u_{11} + u_{22})u_{12} = 0$, i.e. that *either* $u_{11} + u_{22} = 0$ *or* $u_{12} = 0$ (or both).  But $U$ wasn't allowed to be diagonal, so we can't have $u_{12} = 0$, so we must have instead that $u_{11} + u_{22} = 0$, i.e that $u_{22} = -u_{11}$.\n",
    "\n",
    "So, we see that, as long as $u_{22} \\neq 0$, the matrix $$\\boxed{\\begin{pmatrix} 1 & u_{22} \\\\ 0 & -1 \\end{pmatrix}}$$ and its negative are upper-triangular, equal to their own inverse, and not diagonal, and that these are the only such $2 \\times 2$ matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 2** \n",
    "To get the solution more elegantly, let's think about what upper triangular matrices *do*.  $Ux$ only sends information \"upwards\" in $x$, i.e. it adds multiples of later rows to earlier rows (exactly the opposite of what *lower* triangular matrices do in elimination).  What we need is a matrix that sends an entry \"up\" in the first step, but if we do the step twice then it cancels the previous step.\n",
    "\n",
    "Let's start with a really simple upper-triangular matrix, as \"close to $I$\" as possible, making it $4 \\times 4$ to be interesting.\n",
    "$$\n",
    "\\begin{pmatrix} 1 &   &   & 1 \\\\\n",
    "                  & 1 &   &   \\\\\n",
    "                  &   & 1 &   \\\\\n",
    "                  &   &   & 1 \\end{pmatrix}\n",
    "$$\n",
    "which is just the identity matrix plus a single 1 above the diagonal.  If we multiply this by a vector $x$, it adds the first and last rows, and keeps the other rows the same:\n",
    "$$\n",
    "\\begin{pmatrix} 1 &   &   & 1 \\\\\n",
    "                  & 1 &   &   \\\\\n",
    "                  &   & 1 &   \\\\\n",
    "                  &   &   & 1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} =\n",
    "                  \\begin{pmatrix} x_1 + x_4 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n",
    "$$\n",
    "If we multiply by the matrix over and over, it will keep adding \"more\" of $x_4$ to the first row, and we'll never get back to the original vector.  Instead, if we multiply by the matrix a second time, what we want do is *subtract* instead so that we cancel out the previous step.  How can we do that?  *We just need to flip the sign of $x_4$.*  Let's instead use\n",
    "$$\n",
    "\\boxed{U = \\begin{pmatrix} 1 &   &   & 1 \\\\\n",
    "                  & 1 &   &   \\\\\n",
    "                  &   & 1 &   \\\\\n",
    "                  &   &   & -1 \\end{pmatrix}}\n",
    "$$\n",
    "which gives \n",
    "$$\n",
    "U \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} x_1+x_4 \\\\ x_2 \\\\ x_3 \\\\ -x_4 \\end{pmatrix} \n",
    "\\implies U^2 \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}  = \\begin{pmatrix} x_1+x_4-x_4 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n",
    "$$\n",
    "and hence $U^2 = I$.\n",
    "\n",
    "Of course, there are many other possible upper-triangular matrices that follow this general idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** A *symmetric* matrix $S$ is a matrix that equals its transpose: $S = S^T$.   Suppose that $A=A^T$ and $B=B^T$ are two symmetric matrices, and $C$ is some other matrix (possibly nonsymmetric), all of the same size $m\\times m$.  Which of the following are certainly symmetric?\n",
    "\n",
    "* $A^2 - B^2$\n",
    "* $(A+B)(A-B)$ (note that this does *not* generally equal $A^2 - B^2$ ... why?)\n",
    "* $C^T A C$\n",
    "* $A^T C A$\n",
    "* $ABA$\n",
    "* $C + C^T$\n",
    "* $C - C^T$\n",
    "* $ABAB$\n",
    "\n",
    "You can try these with some random matrices to check your answers, but your solutions should explain your answers with equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution** \n",
    "\n",
    "The idea is to just take the transpose in each case and see what you get.  If you get the same thing, the matrix in question was symmetric.  If you don't get the same form, you can usually see why, and you can then cook up some choices of the matrices that really show the result doesn't have to be symmetric.\n",
    "\n",
    "The calculations below use repeatedly the facts that $(X + Y)^T = X^T + Y^T$ and $(XY)^T = Y^TX^T$.  We also of course use the facts that $A^T = A$ and $B^T = B$ each time.\n",
    "\n",
    "* $A^2 - B^2$: MUST be symmetric. Taking transposes, we get $$(A^2 - B^2)^T = (AA)^T - (BA)^T = A^TA^T - B^TB^T = A^2 - B^2$$\n",
    "* $(A+B)(A-B)$: DOES NOT need to be symmetric.  First, multiplying out the expression we get $(A^2 - B^2) + (BA - AB)$.  This *does not have to equal* $A^2 - B^2$ because it's possible that $AB \\neq BA$ (i.e. when $A$ and $B$ don't *commute*.  Taking the transpose gives: $$(A^2 - B^2)^T + (BA - AB)^T = A^2 - B^2 - A^TB^T - B^TAT^ = A^2 - B^2 - (BA - AB).$$  So, we see that $(A + B)(A - B)$ is symmetric if and only if $BA - AB = AB - BA$, i.e. if and only if $AB = BA$, i.e when $A$ and $B$ commute.  We can find symmetric matrices $A$ and $B$ that don't commute pretty easily, for example using our knowledge of row/column operations.  Remember that row operations are achieved by left multiplications, and column operations by right multiplications.  So, if we take $A$ to be the symmetric permutation matrix $$A = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0\\end{pmatrix}$$ then $AB$ will be $B$ with its rows swapped, and $BA$ will be $B$ with its columns swapped.  So, choosing $B$ to be a symmetric matrix that looks different if we swap its rows or columns, for example $$B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2\\end{pmatrix}$$ we get a concrete counterexample.\n",
    "\n",
    "  - **Remark** The matrix $AB - BA$ is called the [*commutator*](https://en.wikipedia.org/wiki/Commutator) of $A$ and $B$, and measures in a sense how/if $A$ and $B$ commute.  It's an extremely important construction that appears all over the place, for example in making precise the [Heisenberg uncertainty principle](https://en.wikipedia.org/wiki/Uncertainty_principle)\n",
    "\n",
    "* $C^T A C$ MUST be symmetric.  Taking transposes, we get: $$(C^TAC)^T = C^TA^TC = C^TAC$$ which is what we started with.\n",
    "* $A^T C A$ DOES NOT need to be symmetric.  Taking transposes we get $$(A^TCA)^T = A^TC^TA$$ but we don't have to have that $C = C^T$. In fact, if $A$ is invertible, then so is $A^{-1}$, so we can \"cancel\" the $A^T$ on the left and the $A$ on the right when comparing $(A^TCA)^T = A^TC^TA$ and $A^TCA$, obtaining $C = C^T$, so $A^TCA$ is symmetric if and only if $C$ is symmetric (again, when $A$ is invertible).  So choosing $A = I$ and $C$ anything non-symmetric will produce a non-symmetric matrix $A^TCA$.\n",
    "* $ABA$ MUST be symmetric.  Taking transposes, we get $$(ABA)^T = A^TB^TA^T = ABA,$$ the same as we started with.  More generally, any [palindrome](https://en.wikipedia.org/wiki/Palindrome) product of symmetric matrices will still be symmetric.\n",
    "* $C + C^T$ MUST be symmetric.  Taking transposes, we get $$(C + C^T) = C^T + C = C + C^T,$$ the same as we started with.\n",
    "* $C - C^T$ DOES NOT need to be symmetric.  Taking transposes, we get $$(C - C^T)^T = C^T - C = -(C - C^T),$$ the *negative* of what we started with.  The only way a matrix can be equal to its negative is if it was already $0$; so the only way $C - C^T$ can be symmetric is if it was zero already, i.e. if $C = C^T$, i.e. if $C$ was symmetric.  So any non-symmetric $C$ will give a counterexample.\n",
    "\n",
    "  - **Remark** A matrix $X$ that satisfies $X^T = -X$ is called *antisymmetric*.  It's a basic fact that any matrix can be written uniquely as a sum of a symmetric matrix with an antisymmetric matrix.  Indeed, if $X$ is any square matrix, we can write $$X = \\frac{X + X^T}{2} + \\frac{X - X^T}{2}$$ and the first term is symmetric (by two bullet points up) and the second term is anti-symmetric (by one bullet point up).  The uniqueness can be seen like this.  Suppose $X = Y + Z = Y' + Z'$ where $Y, Y'$ are symmetric and $Z, Z'$ are antisymmetric.  Then $Y - Y' = Z - Z'$.  But as $Y, Y'$ are symmetric, so is $Y - Y'$.  As $Z, Z'$ are antisymmetric, so is $Z - Z'$.  But $Y - Y'$ and $Z - Z'$ are equal, and the only matrix that is simultaneously symmetric and antisymmetric is the 0 matrix; so $Y - Y' = Z - Z' = 0$, so $Y = Y$ and $Z = Z'$ and the decompositions $X = Y + Z = Y' + Z'$ were the same to begin with!  As a final note, if we think of a $m \\times m$ matrix as a vector of length $m^2$, then any symmetric matrix is orthogonal to any antisymmetric matrix (why?), so the above actually shows that the *subspaces* of symmetric and anti-symmetric matrices are orthogonal complements of one another.\n",
    "\n",
    "* $ABAB$ DOES NOT need to be symmetric.  Taking transposes, we get $$(ABAB)^T = B^TA^TB^TA^T = BABA$$ so for $ABAB$ to by symmetric means that $ABAB = BABA$.  We can cook up a counterexample using a similar strategy to what we did in the $(A - B)(A + B)$ problem.  In particular, let's just choose some random matrices $A, B$ that are symmetric; they probably won't commute very well, and so $ABAB$ and $BABA$ should be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
